import asyncio
import contextlib
import json
import mimetypes
import shutil
import tempfile
import time
from pathlib import Path
from typing import Iterable, Optional
from uuid import uuid4

try:
    import resource
except ImportError:  # pragma: no cover - not available on Windows
    resource = None

from ..config import get_settings


class CodeExecutionError(RuntimeError):
    """Raised when the sandboxed execution fails."""


def _resolve_dataset_source(
    dataset_filename: str,
    upload_dir: Path,
    user_id: Optional[int],
) -> Optional[Path]:
    """Resolve dataset file within the user-specific upload directory."""
    relative = Path(dataset_filename)
    if relative.is_absolute() or any(part in ("..", "") for part in relative.parts):
        raise CodeExecutionError("Invalid dataset path provided.")

    expected_prefix = f"user_{user_id}" if user_id is not None else None
    candidates: list[Path] = []

    if relative.parts and relative.parts[0].startswith("user_"):
        if expected_prefix and relative.parts[0] != expected_prefix:
            raise CodeExecutionError("Dataset not accessible for current user.")
        candidates.append(upload_dir / relative)
    else:
        if expected_prefix:
            candidates.append(upload_dir / expected_prefix / relative)
        candidates.append(upload_dir / relative)

    seen: set[Path] = set()
    for candidate in candidates:
        if candidate in seen:
            continue
        seen.add(candidate)
        if candidate.exists():
            return candidate
    return None


def _limit_resources(memory_mb: int) -> None:
    """
    åº”ç”¨èµ„æºé™åˆ¶åˆ°å­è¿›ç¨‹ã€‚

    é™åˆ¶é¡¹ï¼š
    - å†…å­˜ï¼ˆRLIMIT_ASï¼‰
    - CPU æ—¶é—´ï¼ˆRLIMIT_CPUï¼‰
    - è¿›ç¨‹æ•°ï¼ˆRLIMIT_NPROCï¼‰
    - æ–‡ä»¶å¤§å°ï¼ˆRLIMIT_FSIZEï¼‰
    - æ‰“å¼€æ–‡ä»¶æ•°ï¼ˆRLIMIT_NOFILEï¼‰
    """
    if resource is None:
        return  # Windows ä¸æ”¯æŒ

    limit_bytes = memory_mb * 1024 * 1024 if memory_mb > 0 else 768 * 1024 * 1024

    def _clamp(value: int, limit: int) -> int:
        if value in (-1, resource.RLIM_INFINITY):
            return limit
        return min(limit, value)

    try:
        # ğŸ”’ å†…å­˜é™åˆ¶
        soft, hard = resource.getrlimit(resource.RLIMIT_AS)
        resource.setrlimit(resource.RLIMIT_AS, (_clamp(soft, limit_bytes), _clamp(hard, limit_bytes)))

        # ğŸ”’ CPU æ—¶é—´é™åˆ¶ï¼ˆé˜²æ­¢æ— é™å¾ªç¯ï¼‰
        resource.setrlimit(resource.RLIMIT_CPU, (120, 120))  # æœ€å¤š 120 ç§’ CPU æ—¶é—´

        # ğŸ”’ å­è¿›ç¨‹æ•°é‡é™åˆ¶ï¼ˆé˜²æ­¢ fork ç‚¸å¼¹ï¼‰
        resource.setrlimit(resource.RLIMIT_NPROC, (10, 10))  # æœ€å¤š 10 ä¸ªå­è¿›ç¨‹

        # ğŸ”’ æ–‡ä»¶å¤§å°é™åˆ¶ï¼ˆé˜²æ­¢ç£ç›˜å¡«æ»¡ï¼‰
        max_file_size = 50 * 1024 * 1024  # 50MB
        resource.setrlimit(resource.RLIMIT_FSIZE, (max_file_size, max_file_size))

        # ğŸ”’ æ‰“å¼€æ–‡ä»¶æ•°é™åˆ¶
        resource.setrlimit(resource.RLIMIT_NOFILE, (64, 64))  # æœ€å¤š 64 ä¸ªæ‰“å¼€æ–‡ä»¶

    except (ValueError, OSError) as e:
        # æŸäº›å¹³å°ä¸å…è®¸é™ä½é™åˆ¶ï¼›è®°å½•ä½†ç»§ç»­
        import logging
        logging.getLogger(__name__).warning(f"Failed to set resource limits: {e}")
        pass


async def run_python_code(
    code: str,
    *,
    dataset_filename: Optional[str] = None,
    task_id: Optional[int] = None,
    extra_requirements: Optional[Iterable[str]] = None,
    timeout: Optional[int] = None,
    user_id: Optional[int] = None,
) -> dict:
    """
    åœ¨ä¸´æ—¶å·¥ä½œç›®å½•ä¸­æ‰§è¡Œ Python ä»£ç ã€‚

    å®‰å…¨æªæ–½ï¼š
    - ä¸´æ—¶éš”ç¦»ç›®å½•
    - èµ„æºé™åˆ¶ï¼ˆå†…å­˜ã€CPUã€è¿›ç¨‹æ•°ã€æ–‡ä»¶å¤§å°ï¼‰
    - ç½‘ç»œè®¿é—®é˜»æ–­
    - æ–‡ä»¶ç³»ç»Ÿé™åˆ¶
    - è¶…æ—¶æ§åˆ¶
    """
    settings = get_settings()
    timeout = timeout or settings.max_code_execution_seconds

    async def _execute() -> dict:
        with tempfile.TemporaryDirectory(prefix="llm-data-lab-") as tmpdir:
            tmp_path = Path(tmpdir)
            script_path = tmp_path / "analysis.py"

            # ğŸ”’ åœ¨ç”¨æˆ·ä»£ç å‰æ·»åŠ å®‰å…¨é™åˆ¶ä»£ç 
            security_preamble = """
# ===== å®‰å…¨é™åˆ¶ä»£ç ï¼ˆç”±ç³»ç»Ÿè‡ªåŠ¨æ·»åŠ ï¼‰=====
import sys
import os

# ğŸ”’ ç¦ç”¨å±é™©æ¨¡å—çš„å¯¼å…¥
_DANGEROUS_MODULES = {
    'subprocess', 'os.system', 'commands', 'popen2',
    'multiprocessing', 'threading', 'asyncio.subprocess',
    'socket', 'urllib', 'urllib2', 'urllib3', 'requests', 'httpx',
    '__builtin__', '__builtins__', 'builtins',
}

# ğŸ”’ è¦†ç›–å†…ç½®å‡½æ•°ä»¥ç¦ç”¨å±é™©æ“ä½œ
_original_import = __builtins__.__import__

def _safe_import(name, *args, **kwargs):
    # å…è®¸æ•°æ®åˆ†æç›¸å…³çš„å®‰å…¨æ¨¡å—
    if any(name.startswith(dangerous) for dangerous in _DANGEROUS_MODULES):
        # å…è®¸éƒ¨åˆ† os æ¨¡å—åŠŸèƒ½ï¼ˆä»…æ–‡ä»¶è·¯å¾„æ“ä½œï¼‰
        if name == 'os':
            import os as _os
            # åªæš´éœ²å®‰å…¨çš„è·¯å¾„æ“ä½œ
            class SafeOS:
                path = _os.path
                environ = {'DATASET_PATH': _os.environ.get('DATASET_PATH', '')}
            return SafeOS()
        # å…¶ä»–å±é™©æ¨¡å—ä¸€å¾‹æ‹’ç»
        raise ImportError(f"Module '{name}' is disabled for security reasons")
    return _original_import(name, *args, **kwargs)

__builtins__.__import__ = _safe_import

# ===== ç”¨æˆ·ä»£ç å¼€å§‹ =====
"""
            # ç»„åˆå®‰å…¨ä»£ç å’Œç”¨æˆ·ä»£ç 
            full_code = security_preamble + code
            script_path.write_text(full_code, encoding="utf-8")

            dataset_path = None
            if dataset_filename:
                source = _resolve_dataset_source(dataset_filename, settings.upload_dir, user_id)
                if source and source.exists():
                    dataset_path = tmp_path / source.name
                    shutil.copy2(source, dataset_path)
                    original_name = None
                    parts = source.name.split("_", 1)
                    if len(parts) == 2 and parts[1]:
                        original_name = parts[1]
                    if original_name and original_name != dataset_path.name:
                        shutil.copy2(source, tmp_path / original_name)

            # ğŸ”’ å®‰å…¨çš„æœ€å°ç¯å¢ƒå˜é‡ï¼ˆç¦ç”¨ç½‘ç»œè®¿é—®ï¼‰
            env = {
                "PATH": "/usr/bin:/bin",  # æœ€å°è·¯å¾„
                "PYTHONUNBUFFERED": "1",
                "HOME": str(tmp_path),  # éš”ç¦»ä¸»ç›®å½•
                "TMPDIR": str(tmp_path),  # é™åˆ¶ä¸´æ—¶æ–‡ä»¶ä½ç½®
                # ğŸ”’ ç¦ç”¨ç½‘ç»œç›¸å…³åŠŸèƒ½
                "http_proxy": "http://127.0.0.1:1",  # ä½¿æ— æ•ˆä»£ç†é˜»æ­¢ç½‘ç»œ
                "https_proxy": "http://127.0.0.1:1",
                "HTTP_PROXY": "http://127.0.0.1:1",
                "HTTPS_PROXY": "http://127.0.0.1:1",
                "no_proxy": "",  # ä¸å…è®¸ç»•è¿‡ä»£ç†
                "NO_PROXY": "",
            }
            if dataset_path:
                env["DATASET_PATH"] = str(dataset_path)

            cmd = ["python3", str(script_path)]

            process = await asyncio.create_subprocess_exec(
                *cmd,
                cwd=str(tmp_path),
                env=env,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                preexec_fn=lambda: _limit_resources(settings.max_code_execution_memory_mb),
            )

            try:
                stdout, stderr = await asyncio.wait_for(process.communicate(), timeout=timeout)
            except asyncio.TimeoutError as exc:
                process.kill()
                raise CodeExecutionError(f"Code execution exceeded {timeout}s timeout.") from exc

            artifact_entries: list[dict] = []
            artifacts_manifest = tmp_path / "artifacts.json"
            manifest_items: list[str] = []
            if artifacts_manifest.exists():
                with contextlib.suppress(json.JSONDecodeError):
                    manifest_data = json.loads(artifacts_manifest.read_text("utf-8"))
                    if isinstance(manifest_data, dict):
                        manifest_items = manifest_data.get("artifacts") or manifest_data.get("files") or []
                    elif isinstance(manifest_data, list):
                        manifest_items = manifest_data

            if not manifest_items:
                manifest_items = [
                    str(path.relative_to(tmp_path))
                    for path in tmp_path.rglob("*")
                    if path.is_file() and path.suffix.lower() in {".png", ".jpg", ".jpeg", ".svg", ".gif"}
                ]

            artifact_folder = None
            if manifest_items:
                if user_id is not None:
                    if task_id:
                        run_identifier = f"user_{user_id}_task_{task_id}"
                    else:
                        run_identifier = f"user_{user_id}_run_{uuid4().hex[:10]}"
                else:
                    run_identifier = f"task_{task_id}" if task_id else f"run_{uuid4().hex[:10]}"
                artifact_folder = settings.artifacts_dir / run_identifier
                if artifact_folder.exists():
                    shutil.rmtree(artifact_folder)
                artifact_folder.mkdir(parents=True, exist_ok=True)

                for item in manifest_items:
                    if isinstance(item, dict):
                        name = item.get("path") or item.get("filename") or item.get("name")
                    else:
                        name = item
                    if not name:
                        continue
                    if not isinstance(name, str):
                        name = str(name)
                    source_file = tmp_path / name
                    if not source_file.exists():
                        continue
                    destination_file = artifact_folder / source_file.name
                    shutil.copy2(source_file, destination_file)
                    mimetype, _ = mimetypes.guess_type(destination_file.name)
                    artifact_entries.append(
                        {
                            "filename": destination_file.name,
                            "url": f"/analysis/artifacts/{artifact_folder.name}/{destination_file.name}?ts={int(time.time())}",
                            "mimetype": mimetype,
                        }
                    )

            result = {
                "returncode": process.returncode,
                "stdout": stdout.decode("utf-8"),
                "stderr": stderr.decode("utf-8"),
                "artifacts": artifact_entries,
            }
            return result

    return await _execute()
