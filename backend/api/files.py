import logging
from pathlib import Path
from typing import Optional
from uuid import uuid4

import openpyxl
import pandas as pd
from fastapi import APIRouter, Depends, File, HTTPException, UploadFile
from pandas.errors import EmptyDataError, ParserError

from ..api.dependencies import get_current_user_id
from ..config import get_settings

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/datasets", tags=["datasets"])

# ğŸ”’ æ–‡ä»¶ç­¾åï¼ˆé­”æ•°ï¼‰ç”¨äºéªŒè¯çœŸå®æ–‡ä»¶ç±»å‹
FILE_SIGNATURES = {
    "csv": [
        b"",  # CSV æ²¡æœ‰å›ºå®šç­¾åï¼Œå…è®¸ç©ºå­—èŠ‚å¼€å¤´ï¼ˆå°†é€šè¿‡å†…å®¹éªŒè¯ï¼‰
    ],
    "xlsx": [
        b"PK\x03\x04",  # ZIP æ ¼å¼ï¼ˆXLSX æ˜¯ ZIP å‹ç¼©çš„ XMLï¼‰
    ],
    "xls": [
        b"\xd0\xcf\x11\xe0\xa1\xb1\x1a\xe1",  # Microsoft Office æ—§æ ¼å¼ (OLE2)
    ],
}


def _validate_file_signature(file_bytes: bytes, extension: str) -> bool:
    """
    éªŒè¯æ–‡ä»¶ç­¾åæ˜¯å¦ä¸æ‰©å±•ååŒ¹é…ã€‚

    Args:
        file_bytes: æ–‡ä»¶çš„å‰å‡ ä¸ªå­—èŠ‚
        extension: æ–‡ä»¶æ‰©å±•å

    Returns:
        True if valid, False otherwise
    """
    if extension not in FILE_SIGNATURES:
        return False

    # CSV ç‰¹æ®Šå¤„ç†ï¼šå…è®¸ä»»ä½•å¼€å¤´ï¼Œä½†ä¼šåœ¨åç»­ pandas è§£ææ—¶éªŒè¯
    if extension == "csv":
        return True

    signatures = FILE_SIGNATURES[extension]
    return any(file_bytes.startswith(sig) for sig in signatures)


def _count_csv_rows(path: Path) -> Optional[int]:
    try:
        with path.open("r", encoding="utf-8", errors="ignore") as fh:
            total = sum(1 for _ in fh)
        # subtract header row if present (at least one row read)
        return max(total - 1, 0)
    except OSError:
        return None


def _count_excel_rows(path: Path) -> Optional[int]:
    try:
        workbook = openpyxl.load_workbook(path, read_only=True, data_only=True)
        worksheet = workbook.active
        rows = max(worksheet.max_row - 1, 0)
        workbook.close()
        return rows
    except Exception:
        return None


@router.post("/upload")
async def upload_dataset(
    file: UploadFile = File(...),
    user_id: int = Depends(get_current_user_id),
) -> dict:
    """
    ä¸Šä¼ æ•°æ®é›†æ–‡ä»¶ï¼ˆCSV, XLSX, XLSï¼‰ã€‚

    å®‰å…¨é™åˆ¶ï¼š
    - æ–‡ä»¶å¤§å°é™åˆ¶ï¼ˆé»˜è®¤ 10MBï¼‰
    - MIME ç±»å‹éªŒè¯ï¼ˆæ–‡ä»¶ç­¾åæ£€æŸ¥ï¼‰
    - æµå¼å†™å…¥é˜²æ­¢å†…å­˜æº¢å‡º
    - ç”¨æˆ·éš”ç¦»å­˜å‚¨
    """
    settings = get_settings()

    # 1. éªŒè¯æ–‡ä»¶å
    if not file.filename:
        raise HTTPException(status_code=400, detail="Dataset must include a filename.")

    # 2. éªŒè¯æ‰©å±•å
    extension = Path(file.filename).suffix.lower().lstrip(".")
    if extension not in settings.allowed_upload_extensions:
        raise HTTPException(
            status_code=400,
            detail=f"Unsupported file type. Allowed: {', '.join(settings.allowed_upload_extensions)}"
        )

    # 3. å‡†å¤‡å­˜å‚¨è·¯å¾„
    safe_name = f"{uuid4().hex}_{Path(file.filename).name}"
    user_dir = settings.upload_dir / f"user_{user_id}"
    user_dir.mkdir(parents=True, exist_ok=True)
    destination = user_dir / safe_name

    # 4. æµå¼è¯»å–æ–‡ä»¶ï¼Œæ£€æŸ¥å¤§å°å’Œç±»å‹
    max_size = settings.max_upload_size_mb * 1024 * 1024  # è½¬æ¢ä¸ºå­—èŠ‚
    total_size = 0
    first_chunk = None

    try:
        with destination.open("wb") as f:
            while chunk := await file.read(8192):  # 8KB å—
                # 4a. æ£€æŸ¥æ–‡ä»¶å¤§å°
                total_size += len(chunk)
                if total_size > max_size:
                    raise HTTPException(
                        status_code=413,
                        detail=f"File too large. Maximum size: {settings.max_upload_size_mb}MB"
                    )

                # 4b. éªŒè¯æ–‡ä»¶ç­¾åï¼ˆä»…ç¬¬ä¸€å—ï¼‰
                if first_chunk is None:
                    first_chunk = chunk
                    if not _validate_file_signature(chunk, extension):
                        raise HTTPException(
                            status_code=400,
                            detail=f"File signature does not match extension .{extension}. Possible file type mismatch."
                        )

                # 4c. å†™å…¥æ–‡ä»¶
                f.write(chunk)

        logger.info(
            f"File uploaded: {file.filename} ({total_size} bytes) by user {user_id}"
        )

    except HTTPException:
        # æ¸…ç†å·²å†™å…¥çš„æ–‡ä»¶
        destination.unlink(missing_ok=True)
        raise
    except Exception as exc:
        # æ¸…ç†å¹¶æŠ¥å‘Šæ„å¤–é”™è¯¯
        destination.unlink(missing_ok=True)
        logger.error(f"Upload failed for {file.filename}: {exc}")
        raise HTTPException(status_code=500, detail="File upload failed") from exc

    # 5. è§£æå’ŒéªŒè¯æ•°æ®é›†
    try:
        if extension == "csv":
            df = pd.read_csv(destination, nrows=500)
            total_rows = _count_csv_rows(destination)
        else:  # xlsx, xls
            df = pd.read_excel(destination, nrows=500)
            total_rows = _count_excel_rows(destination)

    except ParserError as exc:
        destination.unlink(missing_ok=True)
        logger.warning(f"CSV parse error for {file.filename}: {exc}")
        raise HTTPException(
            status_code=400,
            detail=f"Invalid CSV format: {str(exc)[:100]}"
        ) from exc
    except EmptyDataError:
        destination.unlink(missing_ok=True)
        logger.warning(f"Empty file uploaded: {file.filename}")
        raise HTTPException(status_code=400, detail="File is empty")
    except PermissionError as exc:
        destination.unlink(missing_ok=True)
        logger.error(f"Permission error for {file.filename}: {exc}")
        raise HTTPException(status_code=500, detail="File system permission error") from exc
    except Exception as exc:
        destination.unlink(missing_ok=True)
        logger.error(f"Failed to parse {file.filename}: {exc}")
        raise HTTPException(
            status_code=400,
            detail=f"Failed to parse dataset: {str(exc)[:100]}"
        ) from exc

    # 6. ç”Ÿæˆé¢„è§ˆå’Œå…ƒæ•°æ®
    preview = df.head(20).to_dict(orient="records")
    schema_preview = {col: str(dtype) for col, dtype in df.dtypes.items()}
    row_count = total_rows if total_rows is not None else len(df)
    relative_name = destination.relative_to(settings.upload_dir)

    logger.info(
        f"Dataset parsed successfully: {file.filename} ({row_count} rows, {len(df.columns)} columns)"
    )

    return {
        "filename": str(relative_name),
        "original_filename": file.filename,
        "columns": list(df.columns),
        "schema": schema_preview,
        "preview": preview,
        "rows": row_count,
    }
